\edef\mychapter{Mathematical Logic}
\edef\mychapterdate{\date}

\chapter{\mychapter}

\section{Formal Logic}
To begin our mathematical journey, let's start by formalizing the notion of logic.
If one ponders it deeply, math, at its core, is just a game of manipulating a finite set of symbols based on a given set of rules and procedures.
So, let's begin by defining the following:

An \textbf{alphabet} is a set of symbols that can consist of letters, numbers, arrows, mathematical symbols, etc.

A \textbf{formula} is a string of symbols along with some rule for determining whether a given string is a valid formula.
We called these valid formulae \textit{well-formed}.
For example, if our alphabet consisted of the symbols $\{A, B,+\}$, we can say every valid formula in our system is a finite string where $A$ and $B$ are not adjacent.
Hence, the following formulae are well-formed:
$$A+B+, \quad A++B,$$
and the following are not well-formed:
$$ABA+AB, \quad A++BA.$$

With these definitions out of the way, let's define the idea of a proof.
Because we want our formal system to be as general as possible, our definition of a proof might not seem at first like a proof.
But as we use these ideas to develop first propositional logic and then first-order logic, the motivation for such a definition might start to become more apparent.

With that, we start by defining a \textbf{proof} to be an ordered list of formulae where each element is either given by an \textbf{axiom} or by a \textbf{rule of inference} from any previous statements.

An \textbf{axiom} is a set of well-formed formulae.
To help define an axiom, it is common to specify an \textbf{axiom schema}, which is a mechanical rule for determining whether a statement is an axiom.
Continuing with our system as defined before, we can define the set
$$\mathbb{A}=\{A+A,A+B, A+B, B+B\}$$
to be the set of axioms.
Alternatively, we define this set using an axiom schema by saying
$$\textit{A formula is an axiom if it's of the form}$$
$$a+b$$
$$\textit{for $a,b=A$ or $a,b=B$}.$$

Then, a \textbf{rule of inference} is a rule for assigning a certain set of formulas to a new formula.
As an example, let's define the following rule in our system:
$$\textit{From } A+A \text{ and } B+B, \textit{ infer } +.$$
Taking all of this, we could construct the following proof:
\begin{enumerate}[label=(\arabic*)]
	\item B+B
	\item A+B
	\item A+A
	\item +
\end{enumerate}
where (1), (2), and (3) are from our axioms, and (4) is inferred by our rule of inference.

Finally, the formula listed at the end of a proof is a \textbf{theorem}, where the entire proof can be denoted as the proof of said theorem.
Our previous example can be thought of as the proof for the theorem $+$.

\section{Propositional Logic}
Now that we have formalized the notion of logic, let's start to actually do something a bit more useful.
Due to the generality of a formal system of logic, without additional structure, it's really hard to make sense of just some arbitrary system.
For example, in our preceding section, we made no mention of the notion of truth, which should be a core concept in any logic system that does anything mathematical.

\subsection{Seeking Motivation}
In this section, we will start by using our intuition to understand how we want to build our formal system in a way that fits our perception of reality.
After all, a system that resembles very little what we might think may be of little use in our journey to formalize \textit{human} thought.

Let's start by examining the properties of manipulating simple true/false expressions.
When examining true/false statements, our variables only evaluate to two outcomes; it's often convenient to prove theorems or define operations in what's called a \textbf{truth table}.
Let's show this by defining the operators we seek to use in this way.

First, we define the \textbf{conjunction} operator, denoted as $p\wedge q$, where $p,q$ are variables that either evaluate as T or F. As seen in figure \eqref{fig:conjunction}, the possible evaluations of $p$ are listed in the leftmost column.
Similarly, the middle column lists the possible evaluations of $q$.
The rightmost column lists the evaluations of $p\wedge q$, given the evaluations of $p$ and $q$ in the same row.

\begin{figure}[h]
	\centering
	\begin{tabular}{ |c|c|c| }
		\hline
		$p$ & $q$ & $p\wedge q$ \\
		\hline
		T & T & T \\
		\hline
		T & F & F\\
		\hline
			F & T & F\\
		\hline
		F & F & F\\
		\hline
	\end{tabular}
	\caption{}
	\label{fig:conjunction}
\end{figure}

As such, examining the truth table, one finds that the conjunction operator functions eerily similarly to \textit{and} in the English language.
This is no mistake, as the word \textit{and} can be thought of as the conjunction operator in the English language.

Next, we can define the disjunction operator, denoted as $p\vee q$, which has the truth table given in figure \eqref{fig:disjunction}.
As one might expect, disjunction is essentially the word \textit{or} in the English language.

\begin{figure}[h]
	\centering
	\begin{tabular}{ |c|c|c| }
		\hline
		$p$ & $q$ & $p\vee q$ \\
		\hline
		T & T & T \\
		\hline
		T & F & T\\
		\hline
		F & T & T\\
		\hline
		F & F & F\\
		\hline
	\end{tabular}
	\caption{}
	\label{fig:disjunction}
\end{figure}

Finally, we define the negation operation, denoted as $\neg \, p$, which contrary to disjunction and conjunction, is a unary operator\footnote{
Acting on one input.}
The truth table of negation is shown in figure \eqref{fig:negation} and, as one expects, is essentially the not operator.

\begin{figure}[h]
	\centering
	\begin{tabular}{ |c|c| }
		\hline
		$p$  & $\neg \, p$ \\
		\hline
		T & F \\
		\hline
		F & T \\
		\hline
	\end{tabular}
	\caption{}
	\label{fig:negation}
\end{figure}

We will, however, not be referring to these operators by their technical names and instead be referring to $p\vee q$ as \textbf{or}, $p\wedge q$ as \textbf{and}, and $\neg \, p$ as \textbf{not}.

Now, let's examine the properties of these operations.
First, we note that the binary operations are both \textbf{commutative} and \textbf{associative}.
The truth tables for either are similar. Therefore, I only show \textbf{or} in figure \eqref{fig:com-aso-bool}.

\begin{figure}[h]
\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		$p$ & $q$ & $p \vee q$ & $q \vee p$\\
		\hline
		T & T & T & T\\
		\hline
		T & F & T & T\\
		\hline
		F & T & T & T\\
		\hline
		F & F & F & F\\
		\hline
	\end{tabular}\\ [1em]
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		$p$ & $q$ & $r$ & $(p \vee q) \vee r$ & $p \vee (q \vee r)$\\
		\hline
		T & T & T & T & T\\
		\hline
		T & T & F & T & T\\
		\hline
		T & F & T & T & T\\
		\hline
		T & F & F & T & T\\
		\hline
		\multicolumn{5}{|c|}{\vdots}
	\end{tabular}
	\caption{}
	\label{fig:com-aso-bool}
\end{figure}

For the binary operations, we notice that T and F act in a way like identity elements,
$$p \vee \text{F} = p \jand  p \wedge \text{T} = p$$
like the elements 0 and 1 do for addition and multiplication.
Now, to this point, it seems more and more that the \textbf{or} and the \textbf{and} operators are operating more and more like addition and multiplication.

Applying our observations that these operations operated quite similarly to addition and multiplication, we should expect
$$p\wedge (q \vee r) = (p\wedge q ) \vee (q \wedge r).$$
If one were to construct these statements' truth tables, we would find they indeed match up.

Now, whilst these parallels are nice, we have gotten to the point where this analogy starts to diverge.
By constructing the truth table for
$$p\vee (q \wedge r),$$
one would find this is equivalent to the truth table for
$$(p\vee q) \wedge (p\vee r)$$
suggesting that $\vee$ \textit{also} distributes over $\wedge$.

Up to this point, it seems that by interchanging every $\vee$ and $\wedge$, then every T and F, the truthfulness of an identity remains unchanged.
If this statement were true, it would help us substantially, as if we established some theorem, by simply interchanging the symbols, we would get another true statement.
Well, with a stroke of luck, this is precisely the case for $\vee$ and $wedge$ in. Math, we called these relations \textbf{duality principles}, and when they exist, they become a very powerful tool.
Without getting too specific with the definitions here, concepts are dual roughly when they are defined anti-symmetrically to each other.
Thus, due to the symmetry, with the inverted parts reversed, the same proof may be repeated.

In our case, $\wedge$ is \textit{dual} to $\vee$.
The proof of this duality principle should be immediately obvious by observing our definitions for $\vee$ and $\wedge$:
If we interchange T and F in the definition for $\vee$, we get the definition for $\wedge$ and vice versa.

Interchanging T and F, we find $\vee$ can by defined in terms of $\wedge$ as follows:
$$p \vee q = \neg (\neg p \wedge \neg q)\footnotemark$$
Then by observing
$$\neg \neg r = r$$
for any $r$, we have the identity
$$\neg (p\vee q) = \neg \neg (\neg p \wedge \neg q)= \neg p \wedge \neg q.$$
This is what's known as \textbf{De Morgan's law}, and by duality, we also have
$$\neg (p\wedge q) =\neg p \vee \neg q.$$

\footnotetext{I should note, to simplify notation, we will be imposing an order of operations: Namely, we evaluate $\neg$ before $\vee$ and $\wedge$ when parentheses are not present.}

After these, we have the complement law, which also comes in pairs, namely
$$p \vee \neg p = \text{T}, \quad p \wedge \neg p = \text{F}.$$
In some sense, we can describe $\neg$ as the \textit{inverse assigning} operator, similar to how $-$ assigns inverses with addition (i.e., $a+(-a)=0$), except the inverse assigning operator is the same for both operations by duality.

The two remaining identities that are of importance are fairly trivial to see, and we won't go too in-depth into them. These results are the
\begin{center}
	\begin{tabular}{rl}
	Idempotent Laws: & $p \vee p = p, \quad p \wedge p = p$, \\
	Absorption Laws: & $p \vee (p \wedge q) = p \wedge (p \vee q) = p$.
\end{tabular}
\end{center}

\subsection{Formalization}
Now, let's take our observations and define a formal system that reproduces these properties.
It might be good to stop at this time and first discuss why it might be a good idea to formalize logic.
After all, isn't what we have above almost good enough for most purposes?\footnote{
I say almost here, since to actually describe math, we are still missing a few key pieces, like quantifiers. We will discuss this soon.}

Well, if we were to just stick with higher-level structures,  like those seen in algebra or geometry, this is as far as we probably need to go in terms of \textit{formalizing} logic, in fact, the remaining sections on propositional logic can be skipped with no loss of continuity (except for a few inconsequential examples).
However, defining propositional logic as a formal system also has its advantages.
For one, by giving it a rigorous definition, one could treat propositional logic as a \textit{mathematical object}.
Throughout this book, we will develop different methods to interpret and manipulate different mathematical objects to reveal hidden properties that said objects might have.
As it turns out, understanding our underlying logic systems has very important applications in not just math but also computer science.
Many studies in theoretical computer science emerge from the study of logical systems; as such, formalizing logic has become of great importance in the past century, as computers have slowly started taking over the world.

Now, with this side tangent out of the way, let's get back to describing what we did in the previous section, by instead in a formal setting.

Whilst we could stick with our \textbf{or}, \textbf{and}, and \textbf{not} operators, as with convention, we usually just reduce this down to just two operators: Namely \textbf{not} and \textbf{implies} ($\to$), or more formally, the \textbf{conditional} operator.

As the name suggests, we should define this new operation in a way that closely resembles the word \textit{implies} in the English language.
Moving back to our informal system of true/false statements, let's examine how we should define this operator.

Let's take the statement
$$\textit{Grey skies implies it rains tomorrow}.$$
Examining when this statement is true, let us first suppose the first part of the statement is never true, hence
$$\textit{The skies are never grey}.$$
In this situation, it doesn't matter whether it rains tomorrow or not; the statement is \textbf{vacuously true} since the first part of the statement is never satisfied.

Now, suppose we observe a grey sky; then, for the statement to be true, we would require it to rain the next day, or the statement becomes a false implication.

With this observation in mind, we come up with the truth table as shown in figure \eqref{fig:truth-implies}.
Comparing this with the truth table of $\neg \,p \vee q$, we can conclude:
$$p \to q = \neg \,p \vee q.$$

\begin{figure}[h]
\centering
	\begin{tabular}{|c|c|c|}
		\hline
		$p$ & $q$ & $p\to q$ \\
		\hline
		T & T & T \\
		\hline
		T & F & F \\
		\hline
		F & T & T \\
		\hline
		F & F & T \\
		\hline
	\end{tabular}
	\caption{}
	\label{fig:truth-implies}
\end{figure}

Now, suppose we had
$$p \to q \jand q \to p,$$
We could replace this with a single new operator, namely
$$p \leftrightarrow q.$$
When we have a conditional operator going in both directions, we call this in logic a \textbf{biconditional} or \textbf{equivalence}.
In plain English, we might call this relation \textbf{if and only if}; hence, we can restate the previous statement as
$$p \textit{ if and only if } q.$$
You can also interpret the biconditional operator as a sort of \textit{logical equivalence}.
We are quite ready to discuss the notion of equivalence yet, but I am introducing this terminology since in math, often you might hear the phrase \textit{the following are equivalent}, and I wanted to make sure I define it here.
The biconditional has the truth table depicted in figure \eqref{fig:truth-biimplies}

\begin{figure}[h]
\centering
	\begin{tabular}{|c|c|c|}
		\hline
		$p$ & $q$ & $p\leftrightarrow q$ \\
		\hline
		T & T & T \\
		\hline
		T & F & F \\
		\hline
		F & T & F \\
		\hline
		F & F & T \\
		\hline
	\end{tabular}
	\caption{}
	\label{fig:truth-biimplies}
\end{figure}

Now, we are ready to define propositional logic.
First, we have our alphabet, which will consist of our alphanumeric characters, each of which will be a well-formed formula, called an \textbf{atomic formula};
the symbols $\to$ and $\neg$, which will make up our \textbf{connectives};
and brackets, to enforce an order of operations.\footnote{
We will stick with our previous convention of evaluation $\neg$ before $\to$ when parentheses are not present.}

We will define every atomic formula as well-formed.
Then we can generate new formulae inductively from the following set of rules:
\begin{enumerate}
	\item If $\phi$ and $\psi$ are both well-formed, then $(\phi\to \psi)$ is also well-formed,
	\item If $\phi$ is well-formed, then $\neg p$ is well-formed.
\end{enumerate}
Namely, a statement is well-formed if a combination of these rules can construct it.

Using this, we can deduce that the following formulae are well-formed:
$$(p \to \neg q) \to \neg q, \quad p, \quad \neg p, \quad ...$$
and the following are \textit{not} well-formed:
$$(p \to \to q), \quad \neg \to p, \quad ...$$
We will also impose that all well-formed formulae are finite.

While not strictly a part of our formal system, we can use the symbols $\vee, \wedge$, and $\leftrightarrow$ to simplify our formulae.
Namely, we define each of these symbols as follows:
\begin{align}
	\phi \vee \psi &:= \neg \phi \to \psi, \\
	\phi \wedge \psi &:= \neg (\phi \to \neg \psi ), \label{eq:and-prop-def}\\
	\phi \leftrightarrow \psi &:= \neg((\phi \to \psi) \to \neg (\psi \to \phi)).\footnotemark
\end{align}
\footnotetext{Of course we can translate the definition of $\phi \leftrightarrow \psi$  to $(\phi \to \psi) \wedge (\psi \to \phi)$ by applying equation \eqref{eq:and-prop-def}.}
letting $\phi$ and $\psi$ be any arbitrary well-formed formulae.

As for axioms, we will have three schemes, namely
\begin{axiomlist}
	\item $\phi \to (\psi \to \phi)$
	\item $[\phi \to (\psi \to \theta)] \to [(\phi \to  \psi) \to (\phi \to \theta)]$
	\item $[(\neg \psi \to \neg \phi) \to (\phi \to \psi)]$
\end{axiomlist}
where $\phi, \psi, \theta$ is any valid formula.

The idea of defining these axioms is that we can provide proofs for true statements in our formal system when we use them.
Now, we haven't determined what it means for a statement to be true or how notions of true and false fit into this model, but once we do, we would need to show that statements with proofs in this system are indeed true.
Also, if we expect proved statements to be true, naturally, the axioms listed here must be true since a one-element proof with any of these axioms is a valid proof of the axiom.

Then, for our rules of inference, we will have one, known by \textit{modus ponens}, which states
$$\textit{Given } p \textit{ and } p \to q, \textit{ infer } q.$$

Using our formal system, we can prove the following:

\begin{thm}
	For any valid formula $p$, $p\to p$ is a theorem in propositional logic.
\end{thm}
\begin{proof}
	The formal proof for this formula goes as follows:
	\begin{enumerate}
		\item $p \to [(p \to p) \to p]$, by (A1)
		\item $(p \to [ (p \to p) \to p]) \to ([p \to (p \to p)] \to (p \to p))$, by (A2)
		\item $[p \to (p \to p)] \to (p \to p)$, by modus ponens
		\item $p \to (p \to p)$, by (A1)
		\item $p \to p$, by modus ponens.
	\end{enumerate}
\end{proof}

Now, like I've mentioned before, the whole point of formalizing logic is to give a means to interpret logic as a mathematical object to study it as such.
%TODO: add proofs of deduction, double negative, and proof by contradiction and contrapositive.

\subsection{Interpretation of Truth}
Now that we've defined how to manipulate and construct proofs in our formal system, let's provide our system with some meaning and discuss the notion of truth.
In propositional logic, we generally deal with two types of statements, \textbf{tautologies} and \textbf{contradictions}.
To define these terms, we need to discuss the \textbf{valuation} of propositional statements.

A valuation is a rule for assigning truth values to formulae in propositional logic.
We recall that each formula in our system can be defined inductively starting from our atomic formulae.
A connective provides the means to construct new formulae from previous ones.
Each connective has an associated truth table, which can be used to define the truth value of our new statement.
Therefore, to consider the truth value of a statement, we require that a truth value be assigned to each atomic formula.

We will define a valuation as the truth value of a statement under our system of true/false statements as defined in our previous section.
By the above observation, we conclude it suffices to consider the valuation of a statement given the valuation of each of its atomic formulae.
We will denote the valuation of a statement $\phi$ with $v_S(\phi)$, where $S$ is a rule for assigning valuations to each atomic formulae.\footnote{
The notation that we've chosen here for valuation resembles the notation for a \textit{function}.
This is no mistake since the valuation operation can be understood as a function taking propositional statements to either a value of true or false.}

\begin{ex}
	Let's consider the valuation of each of our axioms in propositional logic.
	Let's draw our attention first to our first axiom. If $(p)$ and $(q)$ are atomic formulae, we can define our rule $S$ by letting
	%TODO: finish this example.
	\label{ex:val-axioms}
\end{ex}

If for every choice of $S$, the valuation of our statement under each $S$ is true, then we claim this statement is a tautology.
Therefore, by example \eqref{ex:val-axioms}, we deduce that each of our axioms are tautologies.

We define a contradiction as the dual concept to a tautology; if a statement has the valuation of false under any choice of $S$, we deduce that this statement is a contradiction.

In the remainder of this section, we will restrict our attention solely to the discussion of tautological formulae.

Now, the natural question to ask is whether formulae that can be derived as proof are therefore also tautological.
This is a remarkably non-trivial question since, in general, our rules of inference need not interact with valuation in any sensible way.
In other words, formulae derived from our rules of inference need not be tautological for an arbitrary formal system.
In addition, our axioms need not be tautologies, which complicates matters even further.
But, when statements derived from a proof are indeed tautologies, we say this formal system is \textbf{sound}.

\begin{thm}
	Propositional logic is sound.
\end{thm}
\begin{proof}
	We've already shown in example \eqref{ex:val-axioms} that our axioms are tautologies.
	Thus, we check that modus ponens preserves tautologies.

	Suppose $p$ and $p \to q$ are both tautologies.
	Then the result is immediate after examining the truth table in figure \eqref{fig:prop-sound}.

	With these two facts, we prove the soundness of propositional logic.
	Suppose we have a theorem $p$ of length $N$.

	%TODO: finish this
\end{proof}

The next natural, yet non-trivial, question to ask about our logic system is whether our system is \textbf{complete}.
A logic system is complete when every true statement has a proof.
It turns out that more complicated logic systems do not satisfy this property.
But, for the relatively simple ones which we consider here, this property indeed holds.

\begin{thm}
	Propositional logic is complete
\end{thm}
\begin{proof}
	%TODO: Do this proof.
\end{proof}

\section{First-Order Logic}
For its simplicity, propositional logic has very nice properties that are relatively easy to prove.
However, propositional logic doesn't have enough power to express the things we'd like to express in math.
For this reason, mathematicians use a slightly more complex system.
This, in turn, makes completeness and soundness more difficult to prove, but simple enough that these properties still hold.

\subsection{Intuition}
Let's first get a feel for how first-order logic works before we define it as a formal system.

Several differences between propositional and first-order logic are that in first-order logic, our variables represent objects in some \textit{domain of discourse}, as opposed to just truth values.
With these objects, statements become true when these objects satisfy some condition given by a \textit{predicate}.
As a result, sometimes first-order logic is also known by the name \textit{predicate logic}.

A predicate in logic can be thought of simply as a relation between any finite number of terms.
A predicate is true when the collection of terms satisfies the relation.
We call relations requiring $n$ terms \textit{n-nary} relations, and we call relations between two terms or one term a \textit{binary relation} and \textit{unary relation} respectively.
Then, using the same rules as seen in propositional logic, these predicates can be composed to form full statements and evaluated like before for their truth values.
As such, we can think of predicates like functions that take in a set of terms and output true or false; thus, we adopt the following notation
$$\phi(x_1,x_2,...,x_n)$$
for a $n$-nary relation called $\phi$.

Since first-order logic works on sets of objects, we require our system to have \textit{quantifiers}, which quantify how many objects in some domain has to satisfy a given predicate for the statement to be true.
The two quantifiers we use in math are \textbf{there exists} ($\exists$) and \textbf{for all} ($\forall$), more formerly known as the \textit{existential} and \textit{universal} quantifiers.

These are the only two that we need, and every other quantifier can be represented by some combination of these two.

But with a bit more careful analysis, it turns out even two is too many, and we can reduce it down to just one.
Let's explore this idea a bit further by considering the following example:
\begin{equation}
	\textit{Every tree is green.}
	\label{eq:tree-green-ex}
\end{equation}
If we think about when statement \eqref{eq:tree-green-ex} is false, we realize it's precisely false when there is at least one tree \textit{not} green.
Hence, the negation of this statement is precisely
\begin{equation}
	\textit{There exists some tree that's not green.}
	\label{eq:tree-green-ex-neg}
\end{equation}
If we represent the predicate $\textit{is green}$ by the symbol $\phi(x)$, where $x$ represents a tree in some domain, we can represent statement \eqref{eq:tree-green-ex} by
\begin{equation}
	(\forall x)(\phi(x)).
\end{equation}
Then since the predicate $\textit{is not green}$ is precisely the negation of the predicate $\textit{is green}$, thus representing statement \eqref{eq:tree-green-ex-neg} symbolically, we have
\begin{equation}
	(\exists x)(\neg \phi(x)).
\end{equation}
As discussed before, since these statements are negations of each other, we have that
\begin{equation}
	\neg ((\forall x)(\phi(x))
\end{equation}
is logically equivalent to statement \eqref{eq:tree-green-ex-neg}.

As we can see, the existential and universal quantifiers are negations of each other, and hence we can represent one with the other simply by negation.

\subsection{Formalization}
Like before with propositional logic, the remaining sections targeted at formalizing first-order logic can be skipped with no loss of continuity (except for a few inconsequential examples).

To formalize first-order logic, we start with the alphabet we will be working with.
Like before, we use alphanumeric (or Greek) symbols to represent variables, except this time, our variables represent objects in some domain of discourse.
Similar to before, we use the symbols $\to$ and $\neg$ to denote the conditional and negation operators, and use parentheses to group statements together.
To denote predicates, we will adopt the notation from the previous section, and this time we include $\forall$, the universal quantifier.
Note, in our formal system, we didn't make any mention of the existential quantifier.
It turns out that the two quantifiers can be represented in terms of one another; hence, to make defining our formal system easier, it suffices only to include one.

We define the concept of a well-formed formula similarly to before, except that this time, our atomic formulae will consist of the set of all predicates, complete with arbitrary variables.
Hence, the following are examples of atomic formulae:
\begin{equation}
	\phi(x_1,x_2,\dots,x_n), \quad f(1, 2, x, a), \quad h(\alpha,\beta,\gamma),
\end{equation}
and the following are \textit{not} exmaples of well-formed atomic formulae:
\begin{equation}
	\phi( ,\alpha,\beta, ), \quad f(,,).
\end{equation}
These atomic formulae form a basis from which we construct more complex formulae using a similar recursive procedure, which I've listed below for the reader's convenience:
\begin{enumerate}
	\item If $\phi$ and $\psi$ are both well-formed, then $(\phi\to \psi)$ is also well-formed,
	\item If $\phi$ is well-formed, then $\neg p$ is well-formed.
\end{enumerate}
To accommodate quantifiers, first-order logic additionally includes
\begin{enumerate}
	\item If $\phi$ is well-formed and $x$ is any arbitrary variable, then $(\forall x)\phi$ is well-formed.
\end{enumerate}
Following this, we determine that the following formulae are well-formed:
\begin{equation}
	\neg((\forall z)(\phi(x,y,z) \to \psi(a,b))), \quad
	(\forall x)(\phi(x) \to ((\forall w)(\neg \lambda(y,z))))
\end{equation}
and the following formulae are \textit{not} well-formed:
\begin{equation}
	\neg(\phi(,,z)(\forall x) \to), \quad \phi(x,y) \to \psi(x,y)(\forall x)\neg.
\end{equation}

Now, while not officially a part of our formal system, we can define the existential quantifier as
\begin{equation}
	(\exists x)\phi := \neg(\forall x)(\neg \phi)
\end{equation}
and use it to simplify formulae.
We can additionally use $\vee, \wedge$, and $\leftrightarrow$, like we did in propositional logic, to simplify our formulae further.

For axioms, we can inherit the first three from propositional logic, namely
\begin{axiomlist}
	\item $\phi \to (\psi \to \phi)$
	\item $[\phi \to (\psi \to \theta)] \to [(\phi \to  \psi) \to (\phi \to \theta)]$
	\item $[(\neg \psi \to \neg \phi) \to (\phi \to \psi)]$.
\end{axiomlist}
To accommodate the addition of quantifiers, we include the following axioms:
\begin{enumerate}
	\item
\end{enumerate}

... Too be continued ...









